---
title: "A classification analysis of customer churn"
subtitle: "Applied machine learning and big data, fall 2021"
author: "Mikkel Wittenburg Petersen"
date: "`r Sys.Date()`"
toc-title: Contents
output:
  pagedown::html_paged:
    toc: true
    fig_caption: true
    number_sections: true
    css:
      - "../styles/fonts.css"
      - default
      - "../styles/custom-style.css"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(reticulate)
library(gt)
library(gtsummary)
library(tidyverse)
```

```{python}
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, auc
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn import svm
from sklearn.model_selection import GridSearchCV
import numpy as np

```

# Introduction

# Method

## The data set



# Analysis


```{python}
# Import the data
df_churn = pd.read_csv("../data/telecom-churn.csv")

```

```{python}
# #split dataset in features and target variable

x = df_churn.drop('Churn', axis=1)

y = df_churn['Churn']

```


```{python}
# split X and y into training and testing sets

x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.33,random_state = 0, stratify = y)

```


```{python}
# Standardize the predictor variables that aren't binary

preproc = ColumnTransformer(
    transformers=[
        ('scale', StandardScaler(), 
        ["AccountWeeks", "DataUsage", "CustServCalls", "DayMins", "DayCalls", "MonthlyCharge", "OverageFee", "RoamMins"]),
    ],
    remainder="passthrough",
)

x_train = preproc.fit_transform(x_train)

x_test = preproc.fit_transform(x_test)

```

## Logistic regression

```{python, include=FALSE, warning=FALSE}

# Create the hyperparameter grid
c_space = [0.01, 0.1, 1, 10]

param_grid = {'C': c_space, 'penalty': ['l1', 'l2'], 'solver' : ['newton-cg', 'lbfgs', 'liblinear']}

# instantiate the model
logreg_model = LogisticRegression()

# Instantiate the GridSearchCV object: logreg_cv
logreg_cv = GridSearchCV(logreg_model, param_grid, cv=5)

# fit the model with data
logreg_cv.fit(x_train,y_train)

# Predict churn in the test set
logreg_prediction_y = logreg_cv.predict(x_test)

```

```{python}

# Create dataframe with actual and predicted values of y
logreg_prediction_y_series = pd.Series(logreg_prediction_y, name = 'predicted_y')

y_test_actual = y_test.reset_index(drop = True).rename('actual_y')

df_logreg_results = pd.concat([y_test_actual, logreg_prediction_y_series],axis=1)



```


```{r}

df_logreg_results <- py$df_logreg_results %>%
  mutate(actual_y_text = case_when(
    actual_y == 1 ~ "Churn",
    actual_y == 0 ~ "No churn"),
    predicted_y_text = case_when(
      predicted_y == 1 ~ "Churn",
      predicted_y == 0 ~ "No churn"
    ))

```

```{r}

logreg_confusion_matrix <- tbl_cross(
  df_logreg_results,
  row = actual_y_text,
  col = predicted_y_text,
  margin=NULL,
  list(actual_y_text ~ "Actual label", predicted_y_text ~ "Predicted label")
) %>%
  modify_header(
    update = list(
      label ~ "")
  ) %>%
  as_gt() %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.top.color = "white")

logreg_confusion_matrix  

```

```{python}

# Classification report where the output is a dictionary
report_logreg_prediction = classification_report(y_test, logreg_prediction_y, output_dict = True)

# Convert the dict to a dataframe
df_report_logreg_prediction = pd.DataFrame(report_logreg_prediction).transpose().reset_index().rename(columns={'index': 'bar'})

df_report_logreg_prediction[['precision','recall', 'f1-score', 'support']] = df_report_logreg_prediction[['precision','recall', 'f1-score', 'support']].apply(lambda x: pd.Series.round(x, 2))
```

```{r}

# Convert from pandas to R dataframe
df_report_logreg_prediction <- py$df_report_logreg_prediction %>%
  slice(c(1, 2, 5))

```

```{r}

# Publication ready classification report
gt(df_report_logreg_prediction) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.bottom.width= px(3),
              column_labels.border.bottom.color= "black",
              column_labels.border.top.color = "white") %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>% 
  tab_style(
    style = list(
       cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = 1)
  ) %>%
  cols_label(
    bar = ""
  )

```

## K-nearest neighbors

```{python, include=FALSE}

param_grid = {'n_neighbors': np.arange(1, 10)}

# instantiate the model
knn_model = KNeighborsClassifier()

knn_cv = GridSearchCV(knn_model, param_grid, cv=5)

# Fit the model to the training data
knn_cv.fit(x_train, y_train)

# Predict churn in the test set
knn_prediction_y = knn_cv.predict(x_test)

```

```{python}

# Create dataframe with actual and predicted values of y
knn_prediction_y_series = pd.Series(knn_prediction_y, name = 'predicted_y')

y_test_actual = y_test.reset_index(drop = True).rename('actual_y')

df_knn_results = pd.concat([y_test_actual, knn_prediction_y_series], axis=1)

```


```{r}

df_knn_results <- py$df_knn_results %>%
  mutate(actual_y_text = case_when(
    actual_y == 1 ~ "Churn",
    actual_y == 0 ~ "No churn"),
    predicted_y_text = case_when(
      predicted_y == 1 ~ "Churn",
      predicted_y == 0 ~ "No churn"
    ))

```

```{r}

knn_confusion_matrix <- tbl_cross(
  df_knn_results,
  row = actual_y_text,
  col = predicted_y_text,
  margin=NULL,
  list(actual_y_text ~ "Actual label", predicted_y_text ~ "Predicted label")
) %>%
  modify_header(
    update = list(
      label ~ "")
  ) %>%
  as_gt() %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.top.color = "white")

knn_confusion_matrix  

```

```{python}

# Classification report where the output is a dictionary
report_knn_prediction = classification_report(y_test, knn_prediction_y, output_dict = True)

# Convert the dict to a dataframe
df_report_knn_prediction = pd.DataFrame(report_knn_prediction).transpose().reset_index().rename(columns={'index': 'bar'})

df_report_knn_prediction[['precision','recall', 'f1-score', 'support']] = df_report_knn_prediction[['precision','recall', 'f1-score', 'support']].apply(lambda x: pd.Series.round(x, 2))
```

```{r}

# Convert from pandas to R dataframe
df_report_knn_prediction <- py$df_report_knn_prediction %>%
  slice(c(1, 2, 5))

```

<br />
<br />
<br />
<br />
<br />

```{r}

# Publication ready classification report
gt(df_report_knn_prediction) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.bottom.width= px(3),
              column_labels.border.bottom.color= "black",
              column_labels.border.top.color = "white") %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>% 
  tab_style(
    style = list(
       cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = 1)
  ) %>%
  cols_label(
    bar = ""
  )
  

```

## Support vector machines

```{python, include=FALSE}

# Create the hyperparameter grid
parameters = {'C':[1, 10, 20, 30, 40], 'gamma':[0.01, 0.1, 1]}

# instantiate the model
svm_model = svm.SVC(probability=True)

# Instantiate the GridSearchCV object: svm_cv
svm_cv = GridSearchCV(svm_model, parameters)

# Fit the model to the training data
svm_cv.fit(x_train, y_train)

# Predict churn in the test set
svm_prediction_y = svm_cv.predict(x_test)

```

```{python, include=FALSE}

# Create dataframe with actual and predicted values of y
svm_prediction_y_series = pd.Series(svm_prediction_y, name = 'predicted_y')

y_test_actual = y_test.reset_index(drop = True).rename('actual_y')

df_svm_results = pd.concat([y_test_actual, svm_prediction_y_series], axis=1)

```


```{r}

df_svm_results <- py$df_svm_results %>%
  mutate(actual_y_text = case_when(
    actual_y == 1 ~ "Churn",
    actual_y == 0 ~ "No churn"),
    predicted_y_text = case_when(
      predicted_y == 1 ~ "Churn",
      predicted_y == 0 ~ "No churn"
    ))

```

```{r}

svm_confusion_matrix <- tbl_cross(
  df_svm_results,
  row = actual_y_text,
  col = predicted_y_text,
  margin=NULL,
  list(actual_y_text ~ "Actual label", predicted_y_text ~ "Predicted label")
) %>%
  modify_header(
    update = list(
      label ~ "")
  ) %>%
  as_gt() %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.top.color = "white")

svm_confusion_matrix  

```

```{python}

# Classification report where the output is a dictionary
report_svm_prediction = classification_report(y_test, svm_prediction_y, output_dict = True)

# Convert the dict to a dataframe
df_report_svm_prediction = pd.DataFrame(report_svm_prediction).transpose().reset_index().rename(columns={'index': 'bar'})

df_report_svm_prediction[['precision','recall', 'f1-score', 'support']] = df_report_svm_prediction[['precision','recall', 'f1-score', 'support']].apply(lambda x: pd.Series.round(x, 2))
```

```{r}

# Convert from pandas to R dataframe
df_report_svm_prediction <- py$df_report_svm_prediction %>%
  slice(c(1, 2, 5))

```


```{r}

# Publication ready classification report
gt(df_report_svm_prediction) %>%
  tab_options(table.align='left',
              table.width = pct(100),
              column_labels.border.bottom.width= px(3),
              column_labels.border.bottom.color= "black",
              column_labels.border.top.color = "white") %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white")
    ),
    locations = cells_body(
      rows = everything())
  ) %>% 
  tab_style(
    style = list(
       cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = 1)
  ) %>%
  cols_label(
    bar = ""
  )
  

```

## ROC curve 

ROC curve 

```{python}

# Compute predicted probabilities for all models
y_logreg_prob = logreg_cv.predict_proba(x_test)[:,1]
y_knn_prob = knn_cv.predict_proba(x_test)[:,1]
y_svm_prob = svm_cv.predict_proba(x_test)[:,1]

# Generate ROC curve values: fpr, tpr, thresholds for models
fpr1, tpr1, thresh1 = roc_curve(y_test, y_logreg_prob, pos_label=1)
fpr2, tpr2, thresh2 = roc_curve(y_test, y_knn_prob, pos_label=1)
fpr3, tpr3, thresh3 = roc_curve(y_test, y_svm_prob, pos_label=1)

plt.plot(fpr1, tpr1, linestyle='--', label='Logistic Regression')
plt.plot(fpr2, tpr2, linestyle='--', label='K-Nearest Neighbors')
plt.plot(fpr3, tpr3, linestyle='--', label='Support Vector Machines')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for all 3 models')
plt.legend(loc='best')
plt.show()

#plt.clf()

```


# Literature


